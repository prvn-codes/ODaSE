{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string \n",
    "import re\n",
    "import ast\n",
    "import itertools\n",
    "import pandas as ps \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from itertools import combinations, permutations\n",
    "from cleantext import clean   # !pip install clean-text\n",
    "ps.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data file containing data about Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['title','subtitle','description','keywords','url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ps.read_csv('D:/ODASE/Data/dataset.csv')\n",
    "#df.drop(columns=['image','pubdate','video','rank'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = column_names\n",
    "df = df.fillna(\"\")\n",
    "df.drop(index = 1037 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Wine Reviews'</td>\n",
       "      <td>b'130k wine reviews with variety, location, wi...</td>\n",
       "      <td>b\"### Context\\n\\nAfter watching [Somm](http://...</td>\n",
       "      <td>b\"['food and drink', 'critical theory', 'mediu...</td>\n",
       "      <td>https://www.kaggle.com/zynicide/wine-reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'UFO Sightings + Air Quality'</td>\n",
       "      <td>b'UFO (USA / lights) + Air Quality (USA / Poll...</td>\n",
       "      <td>b'This dataset is the result of the fusion of ...</td>\n",
       "      <td>b\"['climate', 'space', 'earth sciences', 'time...</td>\n",
       "      <td>https://www.kaggle.com/infof422henni/ufo-air-q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Safebooru - Anime Image Metadata'</td>\n",
       "      <td>b'1.9 million rows of tag-based anime image me...</td>\n",
       "      <td>b'### Context\\n\\n[Safebooru][1] is a tag-based...</td>\n",
       "      <td>b\"['popular culture', 'visual arts', 'animatio...</td>\n",
       "      <td>https://www.kaggle.com/alamson/safebooru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'QuickDraw Sketches'</td>\n",
       "      <td>b'Sketches and Strokes from the QuickDraw Game'</td>\n",
       "      <td>b'### Context\\n\\nThe dataset consists of the s...</td>\n",
       "      <td>b\"['image processing', 'visual arts', 'drawing...</td>\n",
       "      <td>https://www.kaggle.com/google/tinyquickdraw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'EEG Micro-experiment'</td>\n",
       "      <td>b'Music vs. Reading (3-4 min per condition)'</td>\n",
       "      <td>b\"### Context\\n\\nThis is a tiny self-experimen...</td>\n",
       "      <td>b\"['neuroscience', 'biotechnology', 'small', '...</td>\n",
       "      <td>https://www.kaggle.com/millerintllc/eeg-microe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0                      b'Wine Reviews'   \n",
       "1       b'UFO Sightings + Air Quality'   \n",
       "2  b'Safebooru - Anime Image Metadata'   \n",
       "3                b'QuickDraw Sketches'   \n",
       "4              b'EEG Micro-experiment'   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  b'130k wine reviews with variety, location, wi...   \n",
       "1  b'UFO (USA / lights) + Air Quality (USA / Poll...   \n",
       "2  b'1.9 million rows of tag-based anime image me...   \n",
       "3    b'Sketches and Strokes from the QuickDraw Game'   \n",
       "4       b'Music vs. Reading (3-4 min per condition)'   \n",
       "\n",
       "                                         description  \\\n",
       "0  b\"### Context\\n\\nAfter watching [Somm](http://...   \n",
       "1  b'This dataset is the result of the fusion of ...   \n",
       "2  b'### Context\\n\\n[Safebooru][1] is a tag-based...   \n",
       "3  b'### Context\\n\\nThe dataset consists of the s...   \n",
       "4  b\"### Context\\n\\nThis is a tiny self-experimen...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  b\"['food and drink', 'critical theory', 'mediu...   \n",
       "1  b\"['climate', 'space', 'earth sciences', 'time...   \n",
       "2  b\"['popular culture', 'visual arts', 'animatio...   \n",
       "3  b\"['image processing', 'visual arts', 'drawing...   \n",
       "4  b\"['neuroscience', 'biotechnology', 'small', '...   \n",
       "\n",
       "                                                 url  \n",
       "0       https://www.kaggle.com/zynicide/wine-reviews  \n",
       "1  https://www.kaggle.com/infof422henni/ufo-air-q...  \n",
       "2           https://www.kaggle.com/alamson/safebooru  \n",
       "3        https://www.kaggle.com/google/tinyquickdraw  \n",
       "4  https://www.kaggle.com/millerintllc/eeg-microe...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4620"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:2: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\prasa\\AppData\\Local\\Temp/ipykernel_1684/4237603897.py:2: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if text is not \"\":\n"
     ]
    }
   ],
   "source": [
    "def cleanb(text):\n",
    "    if text is not \"\":\n",
    "        return ast.literal_eval(text)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wine Reviews</td>\n",
       "      <td>130k wine reviews with variety, location, wine...</td>\n",
       "      <td>After watching [Somm](http://www.imdb.com/tit...</td>\n",
       "      <td>[food and drink, critical theory, medium, feat...</td>\n",
       "      <td>https://www.kaggle.com/zynicide/wine-reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFO Sightings + Air Quality</td>\n",
       "      <td>UFO (USA / lights) + Air Quality (USA / Pollut...</td>\n",
       "      <td>This dataset is the result of the fusion of tw...</td>\n",
       "      <td>[climate, space, earth sciences, timelines, na...</td>\n",
       "      <td>https://www.kaggle.com/infof422henni/ufo-air-q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Safebooru - Anime Image Metadata</td>\n",
       "      <td>1.9 million rows of tag-based anime image meta...</td>\n",
       "      <td>[Safebooru][1] is a tag-based image archive m...</td>\n",
       "      <td>[popular culture, visual arts, animation, draw...</td>\n",
       "      <td>https://www.kaggle.com/alamson/safebooru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QuickDraw Sketches</td>\n",
       "      <td>Sketches and Strokes from the QuickDraw Game</td>\n",
       "      <td>The dataset consists of the series of strokes...</td>\n",
       "      <td>[image processing, visual arts, drawing, large...</td>\n",
       "      <td>https://www.kaggle.com/google/tinyquickdraw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EEG Micro-experiment</td>\n",
       "      <td>Music vs. Reading (3-4 min per condition)</td>\n",
       "      <td>This is a tiny self-experiment. The researche...</td>\n",
       "      <td>[neuroscience, biotechnology, small, featured]</td>\n",
       "      <td>https://www.kaggle.com/millerintllc/eeg-microe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "0                      Wine Reviews   \n",
       "1       UFO Sightings + Air Quality   \n",
       "2  Safebooru - Anime Image Metadata   \n",
       "3                QuickDraw Sketches   \n",
       "4              EEG Micro-experiment   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  130k wine reviews with variety, location, wine...   \n",
       "1  UFO (USA / lights) + Air Quality (USA / Pollut...   \n",
       "2  1.9 million rows of tag-based anime image meta...   \n",
       "3       Sketches and Strokes from the QuickDraw Game   \n",
       "4          Music vs. Reading (3-4 min per condition)   \n",
       "\n",
       "                                         description  \\\n",
       "0   After watching [Somm](http://www.imdb.com/tit...   \n",
       "1  This dataset is the result of the fusion of tw...   \n",
       "2   [Safebooru][1] is a tag-based image archive m...   \n",
       "3   The dataset consists of the series of strokes...   \n",
       "4   This is a tiny self-experiment. The researche...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [food and drink, critical theory, medium, feat...   \n",
       "1  [climate, space, earth sciences, timelines, na...   \n",
       "2  [popular culture, visual arts, animation, draw...   \n",
       "3  [image processing, visual arts, drawing, large...   \n",
       "4     [neuroscience, biotechnology, small, featured]   \n",
       "\n",
       "                                                 url  \n",
       "0       https://www.kaggle.com/zynicide/wine-reviews  \n",
       "1  https://www.kaggle.com/infof422henni/ufo-air-q...  \n",
       "2           https://www.kaggle.com/alamson/safebooru  \n",
       "3        https://www.kaggle.com/google/tinyquickdraw  \n",
       "4  https://www.kaggle.com/millerintllc/eeg-microe...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'] = df['title'].apply(lambda x:re.sub(r'\\bnan\\b', \"\", str(x), 0, re.MULTILINE))\n",
    "df['title'] = df['title'].apply(lambda x:re.sub(r'^b\\'(.*)\\'', \"\\\\g<1>\", str(x), 0, re.MULTILINE))\n",
    "\n",
    "df['subtitle'] = df['subtitle'].apply(lambda x:re.sub(r'\\bnan\\b', \"\", str(x), 0, re.MULTILINE))\n",
    "df['subtitle'] = df['subtitle'].apply(lambda x:re.sub(r'^b\\'(.*)\\'', \"\\\\g<1>\", str(x), 0, re.MULTILINE))\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x: re.sub(r'\\bnan\\b', \"\", str(x), 0, re.MULTILINE))\n",
    "df['description'] = df['description'].apply(lambda x: re.sub(r'^b[\\'|\\\"](.*)[\\' | \\\"]', \"\\\\g<1>\", str(x), 0, re.MULTILINE))\n",
    "df['description'] = df['description'].apply(lambda x: x.replace(\"\\\\n\",\"\").replace(\"### Context\\\\n\\\\n\",\"\").replace(\"#\",\"\"))\n",
    "df['description'] = df['description'].apply(lambda x: x.replace(\"Context\",\"\").replace(\"context\",\"\").replace(\"Content\",\"\").replace(\"content\",\"\"))\n",
    "\n",
    "df['keywords'] = df['keywords'].apply(lambda x: re.sub(r'\\bnan\\b', \"[]\", str(x), 0, re.MULTILINE))\n",
    "df['keywords'] = df['keywords'].apply(lambda x:re.sub(r'^b\\\"(.*)\\\"', \"\\\\g<1>\", str(x), 0, re.MULTILINE))\n",
    "df['keywords'] = df['keywords'].apply(lambda x: cleanb(x))\n",
    "# df['keywords'] = df['keywords'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding URLS of Documents to Numeric scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding URL's into unique ID's\n",
    "label_encoder = LabelEncoder()\n",
    "df['url_index'] = label_encoder.fit_transform(df['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4620"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Source, Title and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to Lower case.\n",
    "\n",
    "df['title'] = df['title'].str.lower()\n",
    "df['subtitle'] = df['subtitle'].str.lower()\n",
    "df['description'] = df['description'].str.lower()\n",
    "\n",
    "#Stripped the string.\n",
    "\n",
    "df['title'] = df['title'].str.strip()\n",
    "df['subtitle'] = df['subtitle'].str.strip()\n",
    "df['description'] = df['description'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text in title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df.apply(lambda row: clean(row['title'],fix_unicode=True,no_urls=True,to_ascii=True,lower=True,no_emails=True,),axis=1)\n",
    "df['subtitle'] = df.apply(lambda row: clean(row['subtitle'],fix_unicode=True,no_urls=True,to_ascii=True,lower=True,no_emails=True,),axis=1)\n",
    "df['description'] = df.apply(lambda row: clean(row['description'],fix_unicode=True,no_urls=True,to_ascii=True,lower=True,no_emails=True),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "df['subtitle'] = df['subtitle'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "df['description'] = df['description'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_title'] = df.apply(lambda row: word_tokenize(row['title']),axis=1) \n",
    "df['tokenized_subtitle'] = df.apply(lambda row: word_tokenize(row['subtitle']),axis=1)  \n",
    "df['tokenized_description'] = df.apply(lambda row: word_tokenize(row['description']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine tokens from title and description of a document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc'] = df['tokenized_title'] + df['tokenized_subtitle'] + df['tokenized_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of tokens in a doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wine, reviews, 130k, wine, reviews, with, var...\n",
       "1       [ufo, sightings, air, quality, ufo, usa, light...\n",
       "2       [safebooru, anime, image, metadata, 19, millio...\n",
       "3       [quickdraw, sketches, sketches, and, strokes, ...\n",
       "4       [eeg, microexperiment, music, vs, reading, 34,...\n",
       "                              ...                        \n",
       "4615                          [selu, with, good, init, 2]\n",
       "4616                                [price, per, product]\n",
       "4617    [japan, trade, stats, custom, 2016, data, sub,...\n",
       "4618                            [us, flights, data, 2008]\n",
       "4619                                [iowa, house, prices]\n",
       "Name: doc, Length: 4620, dtype: object"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['doc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword & Non-alphanumeric characters removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop word, digits,non-english alphabets removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(df)):\n",
    "    df['doc'][i] = [w for w in df['doc'][i] if not w in stop_words]\n",
    "    df['doc'][i] = list(filter(lambda w: re.search(\"^[a-zA-Z]{3,}$\", w) is not None, df['doc'][i]))\n",
    "    df['doc'][i] = [w for w in df['doc'][i] if not w.isdigit()] # Remove digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Pronouns (Singular and Plural)\n",
    "for i in range(len(df)):\n",
    "    tagged_doc = pos_tag(df.doc[i])\n",
    "    edited_doc = [word for word,tag in tagged_doc if tag!= 'NNP' and tag!= 'NNPS']\n",
    "    df.doc[i] = edited_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming & Lemmatization of tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming and lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df['doc'][i])):\n",
    "        df['doc'][i][j] = lemmatizer.lemmatize(df['doc'][i][j])\n",
    "        df['doc'][i][j] = stemmer.stem(df['doc'][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['doc'][i] = [w for w in df['doc'][i] if not w in stop_words]\n",
    "    df['doc'][i] = list(filter(lambda w: re.search(\"^[a-zA-Z]{3,}$\", w) is not None, df['doc'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word count in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df.apply(lambda row: Counter(row['doc']),axis=1)  # Adding in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {'wine': 10, 'review': 7, 'varieti': 3, 'locat...\n",
       "1       {'ufo': 4, 'sight': 4, 'air': 3, 'qualiti': 3,...\n",
       "2       {'safebooru': 2, 'anim': 3, 'imag': 7, 'metada...\n",
       "3       {'quickdraw': 3, 'sketch': 2, 'stroke': 5, 'ga...\n",
       "4       {'eeg': 3, 'microexperi': 1, 'music': 3, 'read...\n",
       "                              ...                        \n",
       "4615                    {'selu': 1, 'good': 1, 'init': 1}\n",
       "4616                 {'price': 1, 'per': 1, 'product': 1}\n",
       "4617    {'japan': 2, 'trade': 2, 'stat': 1, 'custom': ...\n",
       "4618                             {'flight': 1, 'data': 1}\n",
       "4619                   {'iowa': 1, 'hous': 1, 'price': 1}\n",
       "Name: word_count, Length: 4620, dtype: object"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total tokens from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dict = Counter()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    counter1 = Counter(df['word_count'][i])\n",
    "    add_dict += counter1\n",
    "    \n",
    "final_dict = dict(add_dict) # Sum of all word_count dictionaries is final dictionary.\n",
    "#print(final_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of BOW (Bag Of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30630"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wine': 37,\n",
       " 'review': 434,\n",
       " 'varieti': 113,\n",
       " 'locat': 735,\n",
       " 'wineri': 2,\n",
       " 'price': 544,\n",
       " 'descript': 674,\n",
       " 'watch': 49,\n",
       " 'sommurl': 1,\n",
       " 'documentari': 4,\n",
       " 'master': 38,\n",
       " 'sommeli': 3,\n",
       " 'wonder': 20,\n",
       " 'could': 294,\n",
       " 'creat': 599,\n",
       " 'predict': 771,\n",
       " 'model': 812,\n",
       " 'identifi': 515,\n",
       " 'blind': 3,\n",
       " 'tast': 19,\n",
       " 'like': 765,\n",
       " 'would': 505,\n",
       " 'first': 536,\n",
       " 'step': 70,\n",
       " 'journey': 10,\n",
       " 'gather': 135,\n",
       " 'data': 11465,\n",
       " 'train': 628,\n",
       " 'plan': 146,\n",
       " 'use': 4710,\n",
       " 'deep': 150,\n",
       " 'learn': 787,\n",
       " 'word': 599,\n",
       " 'descriptionreview': 1,\n",
       " 'still': 113,\n",
       " 'wont': 16,\n",
       " 'abl': 150,\n",
       " 'theoret': 4,\n",
       " 'base': 630,\n",
       " 'give': 141,\n",
       " 'anyon': 82,\n",
       " 'idea': 140,\n",
       " 'accomplish': 19,\n",
       " 'pleas': 411,\n",
       " 'post': 409,\n",
       " 'dataset': 7791,\n",
       " 'contain': 2174,\n",
       " 'three': 272,\n",
       " 'file': 2336,\n",
       " 'column': 636,\n",
       " 'row': 309,\n",
       " 'node': 37,\n",
       " 'click': 41,\n",
       " 'tab': 32,\n",
       " 'see': 654,\n",
       " 'individu': 630,\n",
       " 'columnlevel': 3,\n",
       " 'metadata': 172,\n",
       " 'summari': 156,\n",
       " 'statist': 550,\n",
       " 'acknowledgementsth': 221,\n",
       " 'scrape': 278,\n",
       " 'wineenthusiasturl': 1,\n",
       " 'week': 161,\n",
       " 'june': 103,\n",
       " 'code': 809,\n",
       " 'scraper': 23,\n",
       " 'found': 1132,\n",
       " 'hereurl': 790,\n",
       " 'specif': 350,\n",
       " 'question': 519,\n",
       " 'collect': 1135,\n",
       " 'didnt': 34,\n",
       " 'addressupd': 1,\n",
       " 'feedback': 39,\n",
       " 'user': 646,\n",
       " 'novemb': 58,\n",
       " 'time': 1495,\n",
       " 'around': 230,\n",
       " 'titl': 319,\n",
       " 'pars': 52,\n",
       " 'year': 1282,\n",
       " 'taster': 2,\n",
       " 'name': 1232,\n",
       " 'twitter': 218,\n",
       " 'handl': 50,\n",
       " 'also': 815,\n",
       " 'fix': 42,\n",
       " 'duplic': 53,\n",
       " 'entri': 119,\n",
       " 'issu': 216,\n",
       " 'inspirationi': 60,\n",
       " 'think': 109,\n",
       " 'offer': 96,\n",
       " 'great': 131,\n",
       " 'opportun': 46,\n",
       " 'sentiment': 175,\n",
       " 'analysi': 714,\n",
       " 'text': 728,\n",
       " 'relat': 297,\n",
       " 'overal': 93,\n",
       " 'goal': 178,\n",
       " 'breakthrough': 7,\n",
       " 'interest': 503,\n",
       " 'insightsmodel': 1,\n",
       " 'ufo': 12,\n",
       " 'sight': 33,\n",
       " 'air': 200,\n",
       " 'qualiti': 230,\n",
       " 'usa': 84,\n",
       " 'light': 84,\n",
       " 'pollut': 85,\n",
       " 'level': 425,\n",
       " 'result': 554,\n",
       " 'fusion': 4,\n",
       " 'two': 502,\n",
       " 'datasetsufo': 1,\n",
       " 'urlu': 1,\n",
       " 'urlth': 6,\n",
       " 'combin': 208,\n",
       " 'date': 695,\n",
       " 'latitud': 152,\n",
       " 'longitud': 144,\n",
       " 'order': 250,\n",
       " 'get': 427,\n",
       " 'climat': 54,\n",
       " 'inform': 2307,\n",
       " 'occur': 234,\n",
       " 'usacopi': 1,\n",
       " 'metric': 110,\n",
       " 'brendasoeach': 1,\n",
       " 'five': 111,\n",
       " 'includ': 1793,\n",
       " 'instanc': 115,\n",
       " 'unit': 632,\n",
       " 'measur': 417,\n",
       " 'mean': 407,\n",
       " 'arithmet': 13,\n",
       " 'concentr': 27,\n",
       " 'within': 296,\n",
       " 'given': 346,\n",
       " 'aqi': 6,\n",
       " 'calcul': 164,\n",
       " 'index': 312,\n",
       " 'max': 74,\n",
       " 'valu': 705,\n",
       " 'maximum': 76,\n",
       " 'obtain': 179,\n",
       " 'hour': 184,\n",
       " 'record': 753,\n",
       " 'dayi': 2,\n",
       " 'new': 1768,\n",
       " 'binari': 49,\n",
       " 'variabl': 367,\n",
       " 'call': 286,\n",
       " 'equal': 65,\n",
       " 'otherwis': 74,\n",
       " 'introduc': 47,\n",
       " 'nois': 51,\n",
       " 'observ': 257,\n",
       " 'sightingi': 1,\n",
       " 'later': 61,\n",
       " 'provid': 1149,\n",
       " 'conclusionsfeel': 1,\n",
       " 'free': 211,\n",
       " 'add': 89,\n",
       " 'suggestionsthank': 1,\n",
       " 'safebooru': 6,\n",
       " 'anim': 189,\n",
       " 'imag': 2020,\n",
       " 'million': 341,\n",
       " 'tagbas': 2,\n",
       " 'archiv': 124,\n",
       " 'maintain': 765,\n",
       " 'enthusiast': 19,\n",
       " 'allow': 197,\n",
       " 'tag': 258,\n",
       " 'annot': 214,\n",
       " 'translat': 126,\n",
       " 'comment': 234,\n",
       " 'deriv': 111,\n",
       " 'danbooru': 15,\n",
       " 'differ': 892,\n",
       " 'disallow': 4,\n",
       " 'explicit': 12,\n",
       " 'quit': 45,\n",
       " 'popular': 203,\n",
       " 'august': 103,\n",
       " 'via': 143,\n",
       " 'onlin': 234,\n",
       " 'api': 1189,\n",
       " 'convert': 116,\n",
       " 'csv': 392,\n",
       " 'attribut': 411,\n",
       " 'discard': 11,\n",
       " 'convers': 82,\n",
       " 'make': 550,\n",
       " 'whole': 67,\n",
       " 'littl': 45,\n",
       " 'smallerther': 1,\n",
       " 'metadatath': 4,\n",
       " 'upload': 108,\n",
       " 'safebooruorg': 1,\n",
       " 'rang': 185,\n",
       " 'acknowledgementsbann': 3,\n",
       " 'taken': 249,\n",
       " 'url': 3426,\n",
       " 'inspirationwhat': 66,\n",
       " 'highli': 57,\n",
       " 'correlatedcan': 1,\n",
       " 'miss': 170,\n",
       " 'tagscan': 1,\n",
       " 'score': 379,\n",
       " 'tagssom': 1,\n",
       " 'depend': 104,\n",
       " 'presenc': 22,\n",
       " 'stripe': 4,\n",
       " 'sock': 2,\n",
       " 'impli': 45,\n",
       " 'exist': 139,\n",
       " 'build': 438,\n",
       " 'tree': 97,\n",
       " 'visual': 200,\n",
       " 'quickdraw': 3,\n",
       " 'sketch': 4,\n",
       " 'stroke': 28,\n",
       " 'game': 403,\n",
       " 'consist': 340,\n",
       " 'seri': 282,\n",
       " 'made': 414,\n",
       " 'part': 866,\n",
       " 'googl': 260,\n",
       " 'creativ': 105,\n",
       " 'lab': 32,\n",
       " 'quickdrawwithgooglecom': 1,\n",
       " 'store': 175,\n",
       " 'ndjson': 2,\n",
       " 'format': 407,\n",
       " 'wordnos': 1,\n",
       " 'countrycodea': 1,\n",
       " 'utc': 19,\n",
       " 'recognizedtru': 1,\n",
       " 'draw': 41,\n",
       " 'array': 62,\n",
       " 'follow': 943,\n",
       " 'second': 254,\n",
       " 'addit': 338,\n",
       " 'copi': 92,\n",
       " 'cloud': 57,\n",
       " 'describ': 232,\n",
       " 'april': 80,\n",
       " 'simplifi': 32,\n",
       " 'full': 290,\n",
       " 'link': 309,\n",
       " 'github': 191,\n",
       " 'page': 276,\n",
       " 'inspirationtest': 2,\n",
       " 'eeg': 27,\n",
       " 'microexperi': 1,\n",
       " 'music': 116,\n",
       " 'read': 298,\n",
       " 'min': 22,\n",
       " 'per': 500,\n",
       " 'condit': 195,\n",
       " 'tini': 9,\n",
       " 'selfexperi': 1,\n",
       " 'research': 684,\n",
       " 'goldtip': 1,\n",
       " 'wet': 3,\n",
       " 'electrod': 7,\n",
       " 'ganglion': 1,\n",
       " 'develop': 497,\n",
       " 'board': 85,\n",
       " 'elast': 4,\n",
       " 'cap': 8,\n",
       " 'bluetooth': 11,\n",
       " 'connect': 257,\n",
       " 'python': 203,\n",
       " 'openbci': 1,\n",
       " 'softwar': 173,\n",
       " 'approxim': 120,\n",
       " 'minut': 106,\n",
       " 'bit': 47,\n",
       " 'stream': 52,\n",
       " 'custom': 216,\n",
       " 'voicecontrol': 1,\n",
       " 'iot': 10,\n",
       " 'devic': 111,\n",
       " 'scholarli': 16,\n",
       " 'articl': 332,\n",
       " 'wave': 21,\n",
       " 'signal': 117,\n",
       " 'inspirationif': 7,\n",
       " 'sort': 47,\n",
       " 'hope': 112,\n",
       " 'avail': 1663,\n",
       " 'greatli': 7,\n",
       " 'scale': 107,\n",
       " 'experiment': 25,\n",
       " 'set': 1076,\n",
       " 'prototyp': 5,\n",
       " 'process': 872,\n",
       " 'publish': 490,\n",
       " 'brazilian': 69,\n",
       " 'ecommerc': 32,\n",
       " 'public': 1426,\n",
       " 'olist': 8,\n",
       " 'product': 473,\n",
       " 'info': 71,\n",
       " 'olistwelcom': 1,\n",
       " 'storeurl': 1,\n",
       " 'multipl': 227,\n",
       " 'marketplac': 16,\n",
       " 'brazil': 63,\n",
       " 'featur': 615,\n",
       " 'view': 153,\n",
       " 'dimens': 56,\n",
       " 'statu': 239,\n",
       " 'payment': 105,\n",
       " 'freight': 8,\n",
       " 'perform': 337,\n",
       " 'final': 174,\n",
       " 'written': 108,\n",
       " 'releas': 324,\n",
       " 'geoloc': 31,\n",
       " 'zip': 125,\n",
       " 'latlng': 2,\n",
       " 'coordin': 177,\n",
       " 'real': 250,\n",
       " 'commerci': 127,\n",
       " 'anonymis': 5,\n",
       " 'refer': 387,\n",
       " 'compani': 277,\n",
       " 'partner': 43,\n",
       " 'replac': 51,\n",
       " 'throne': 8,\n",
       " 'hous': 225,\n",
       " 'join': 109,\n",
       " 'market': 254,\n",
       " 'funnel': 6,\n",
       " 'olistw': 1,\n",
       " 'dataseturl': 49,\n",
       " 'may': 675,\n",
       " 'perspect': 29,\n",
       " 'instruct': 33,\n",
       " 'kernelurl': 11,\n",
       " 'gener': 581,\n",
       " 'largest': 115,\n",
       " 'depart': 428,\n",
       " 'small': 163,\n",
       " 'busi': 200,\n",
       " 'channel': 60,\n",
       " 'without': 245,\n",
       " 'hassl': 1,\n",
       " 'singl': 311,\n",
       " 'contract': 92,\n",
       " 'merchant': 16,\n",
       " 'sell': 42,\n",
       " 'ship': 36,\n",
       " 'directli': 72,\n",
       " 'logist': 20,\n",
       " 'websit': 412,\n",
       " 'urlurlaft': 1,\n",
       " 'purchas': 67,\n",
       " 'seller': 31,\n",
       " 'notifi': 11,\n",
       " 'fulfil': 13,\n",
       " 'receiv': 215,\n",
       " 'estim': 322,\n",
       " 'deliveri': 28,\n",
       " 'due': 157,\n",
       " 'satisfact': 18,\n",
       " 'survey': 428,\n",
       " 'email': 191,\n",
       " 'note': 330,\n",
       " 'experi': 171,\n",
       " 'write': 108,\n",
       " 'might': 160,\n",
       " 'item': 189,\n",
       " 'distinct': 30,\n",
       " 'exampl': 403,\n",
       " 'list': 761,\n",
       " 'marketplaceexampl': 1,\n",
       " 'marketplaceurl': 1,\n",
       " 'schemath': 1,\n",
       " 'divid': 104,\n",
       " 'better': 195,\n",
       " 'understand': 228,\n",
       " 'organ': 1636,\n",
       " 'schema': 45,\n",
       " 'work': 645,\n",
       " 'itdata': 1,\n",
       " 'schemaurl': 1,\n",
       " 'classifi': 253,\n",
       " 'datasetw': 1,\n",
       " 'previous': 73,\n",
       " 'remov': 156,\n",
       " 'version': 374,\n",
       " 'intend': 69,\n",
       " 'dont': 136,\n",
       " 'finish': 28,\n",
       " 'previou': 115,\n",
       " 'inspirationher': 9,\n",
       " 'inspir': 384,\n",
       " 'possibl': 277,\n",
       " 'outcom': 92,\n",
       " 'datasetnlp': 1,\n",
       " 'brthi': 5,\n",
       " 'suprem': 12,\n",
       " 'environ': 82,\n",
       " 'dimensionsclusteringbr': 1,\n",
       " 'happi': 86,\n",
       " 'madsal': 1,\n",
       " 'predictionbr': 1,\n",
       " 'youll': 25,\n",
       " 'futur': 132,\n",
       " 'salesdeliveri': 1,\n",
       " 'performancebr': 1,\n",
       " 'find': 686,\n",
       " 'way': 244,\n",
       " 'optim': 48,\n",
       " 'timesproduct': 1,\n",
       " 'brenjoy': 1,\n",
       " 'discov': 44,\n",
       " 'categori': 386,\n",
       " 'prone': 3,\n",
       " 'insatisfactionfeatur': 1,\n",
       " 'engin': 138,\n",
       " 'brcreat': 1,\n",
       " 'rich': 41,\n",
       " 'attach': 42,\n",
       " 'extern': 30,\n",
       " 'acknowledgementsthank': 75,\n",
       " 'fivethirtyeight': 229,\n",
       " 'forecast': 92,\n",
       " 'methodolog': 55,\n",
       " 'explor': 1145,\n",
       " 'histor': 253,\n",
       " 'senat': 38,\n",
       " 'forecaststhi': 1,\n",
       " 'folder': 185,\n",
       " 'behind': 100,\n",
       " 'stori': 212,\n",
       " 'worksurlhead': 1,\n",
       " 'definitionst': 2,\n",
       " 'electionyear': 1,\n",
       " 'electioncandid': 1,\n",
       " 'last': 262,\n",
       " 'nameforecastprob': 1,\n",
       " 'probabl': 88,\n",
       " 'win': 116,\n",
       " 'elect': 263,\n",
       " 'day': 444,\n",
       " 'forecastresult': 1,\n",
       " 'lossfor': 1,\n",
       " 'fivethirtyeighturl': 52,\n",
       " 'host': 1221,\n",
       " 'githuburl': 67,\n",
       " 'kaggl': 1440,\n",
       " 'sourc': 1424,\n",
       " 'pageurl': 681,\n",
       " 'updat': 2314,\n",
       " 'frequenc': 865,\n",
       " 'daili': 623,\n",
       " 'acknowledgementsthi': 946,\n",
       " 'apiurl': 222,\n",
       " 'apiurlthi': 92,\n",
       " 'distribut': 1016,\n",
       " 'intern': 346,\n",
       " 'licens': 580,\n",
       " 'chicago': 457,\n",
       " 'energi': 191,\n",
       " 'usag': 112,\n",
       " 'citi': 1997,\n",
       " 'open': 2105,\n",
       " 'display': 78,\n",
       " 'sever': 260,\n",
       " 'consumpt': 83,\n",
       " 'household': 141,\n",
       " 'industri': 147,\n",
       " 'electr': 61,\n",
       " 'aggreg': 123,\n",
       " 'come': 237,\n",
       " 'peopl': 482,\n",
       " 'natur': 183,\n",
       " 'accentur': 1,\n",
       " 'compris': 55,\n",
       " 'percent': 100,\n",
       " 'block': 98,\n",
       " 'account': 162,\n",
       " 'commun': 347,\n",
       " 'area': 390,\n",
       " 'geograph': 141,\n",
       " 'select': 223,\n",
       " 'characterist': 159,\n",
       " 'censu': 385,\n",
       " 'popul': 415,\n",
       " 'physic': 107,\n",
       " 'occup': 71,\n",
       " 'platform': 658,\n",
       " 'accord': 736,\n",
       " 'amount': 794,\n",
       " 'brought': 609,\n",
       " 'socrata': 510,\n",
       " 'socrataurl': 500,\n",
       " 'assist': 587,\n",
       " 'countless': 503,\n",
       " 'integr': 570,\n",
       " 'bring': 526,\n",
       " 'cover': 705,\n",
       " 'photourl': 491,\n",
       " 'jeff': 15,\n",
       " 'sheldonurl': 1,\n",
       " 'unsplashurl': 494,\n",
       " 'unsplash': 1018,\n",
       " 'uniqu': 809,\n",
       " 'licenseurl': 512,\n",
       " 'food': 223,\n",
       " 'world': 807,\n",
       " 'cup': 61,\n",
       " 'cupthi': 1,\n",
       " 'associ': 262,\n",
       " 'cupurl': 1,\n",
       " 'american': 206,\n",
       " 'favorit': 46,\n",
       " 'global': 192,\n",
       " 'cuisineurlanws': 1,\n",
       " 'key': 113,\n",
       " 'respons': 249,\n",
       " 'rate': 661,\n",
       " 'much': 250,\n",
       " 'tradit': 55,\n",
       " 'cuisin': 21,\n",
       " 'questionsvalu': 1,\n",
       " 'love': 60,\n",
       " 'countri': 632,\n",
       " 'one': 1072,\n",
       " 'best': 220,\n",
       " 'consider': 35,\n",
       " 'counti': 285,\n",
       " 'dislik': 4,\n",
       " 'hate': 27,\n",
       " 'worst': 15,\n",
       " 'worldna': 1,\n",
       " 'unfamiliar': 4,\n",
       " 'fli': 22,\n",
       " 'etiquett': 2,\n",
       " 'surveythi': 5,\n",
       " 'flier': 1,\n",
       " 'say': 73,\n",
       " 'rude': 2,\n",
       " 'reclin': 1,\n",
       " 'airplan': 18,\n",
       " 'seaturlflyingetiquettecsv': 1,\n",
       " 'surveymonkey': 7,\n",
       " 'commiss': 44,\n",
       " 'hip': 5,\n",
       " 'hop': 6,\n",
       " 'candid': 178,\n",
       " 'lyric': 40,\n",
       " 'lyricsthi': 1,\n",
       " 'hiphop': 5,\n",
       " 'turn': 65,\n",
       " 'donald': 48,\n",
       " 'trumpurlgeniushiphoplyricscsv': 1,\n",
       " 'everi': 469,\n",
       " 'mention': 66,\n",
       " 'primari': 155,\n",
       " 'songshead': 1,\n",
       " 'definitioncandid': 1,\n",
       " 'referencedsong': 1,\n",
       " 'song': 156,\n",
       " 'nameartist': 1,\n",
       " 'artist': 78,\n",
       " 'namesenti': 1,\n",
       " 'posit': 320,\n",
       " 'neg': 114,\n",
       " 'neutralthem': 1,\n",
       " 'theme': 25,\n",
       " 'lyricalbumreleased': 1,\n",
       " 'album': 38,\n",
       " 'releaselin': 1,\n",
       " 'lyricsurl': 1,\n",
       " 'geniu': 4,\n",
       " 'linksourc': 1,\n",
       " 'geniusurl': 1,\n",
       " 'util': 81,\n",
       " 'servic': 459,\n",
       " 'york': 1312,\n",
       " 'state': 1951,\n",
       " 'track': 227,\n",
       " 'current': 333,\n",
       " 'deliv': 24,\n",
       " 'jurisdict': 76,\n",
       " 'respect': 115,\n",
       " 'consum': 146,\n",
       " 'complaint': 53,\n",
       " 'monthli': 217,\n",
       " 'luca': 15,\n",
       " 'bravourl': 1,\n",
       " 'septemb': 79,\n",
       " 'trumprel': 1,\n",
       " 'tweet': 404,\n",
       " 'scrap': 36,\n",
       " 'trump': 113,\n",
       " 'iswa': 1,\n",
       " 'presid': 73,\n",
       " 'america': 70,\n",
       " 'tweetsthi': 2,\n",
       " 'conduct': 106,\n",
       " 'compar': 235,\n",
       " 'night': 26,\n",
       " 'databas': 760,\n",
       " 'english': 221,\n",
       " 'wikipedia': 141,\n",
       " 'gensim': 7,\n",
       " 'pretrain': 190,\n",
       " 'produc': 185,\n",
       " 'scienc': 298,\n",
       " 'nashvil': 2,\n",
       " 'meetup': 7,\n",
       " 'introduct': 37,\n",
       " 'ive': 87,\n",
       " 'script': 193,\n",
       " 'check': 180,\n",
       " 'back': 127,\n",
       " 'soon': 26,\n",
       " 'dictionari': 95,\n",
       " 'tfidf': 5,\n",
       " 'latent': 3,\n",
       " 'semant': 48,\n",
       " 'indexinganalysi': 1,\n",
       " 'lsilsa': 1,\n",
       " 'topic': 146,\n",
       " 'dirichlet': 1,\n",
       " 'alloc': 22,\n",
       " 'lda': 2,\n",
       " 'size': 226,\n",
       " 'epoch': 12,\n",
       " 'fasttext': 37,\n",
       " 'acknowledgementshop': 1,\n",
       " 'fledgl': 1,\n",
       " 'scientist': 73,\n",
       " 'suggest': 77,\n",
       " 'notebook': 49,\n",
       " 'play': 200,\n",
       " 'tune': 24,\n",
       " 'manner': 28,\n",
       " 'whatsoev': 2,\n",
       " 'simpli': 42,\n",
       " 'want': 279,\n",
       " 'demonstr': 41,\n",
       " 'apith': 3,\n",
       " 'banner': 26,\n",
       " 'jack': 5,\n",
       " 'chest': 50,\n",
       " 'xray': 70,\n",
       " 'pneumonia': 7,\n",
       " 'illustr': 19,\n",
       " 'patient': 155,\n",
       " 'figur': 78,\n",
       " 'normal': 204,\n",
       " 'left': 94,\n",
       " 'panel': 20,\n",
       " 'depict': 10,\n",
       " 'clear': 35,\n",
       " 'lung': 23,\n",
       " 'abnorm': 30,\n",
       " 'opacif': 1,\n",
       " 'bacteri': 1,\n",
       " 'middl': 40,\n",
       " 'typic': 103,\n",
       " 'exhibit': 24,\n",
       " 'focal': 3,\n",
       " 'lobar': 1,\n",
       " 'consolid': 17,\n",
       " 'case': 296,\n",
       " 'right': 180,\n",
       " 'upper': 13,\n",
       " 'lobe': 1,\n",
       " 'white': 61,\n",
       " 'arrow': 3,\n",
       " 'wherea': 11,\n",
       " 'viral': 5,\n",
       " 'manifest': 6,\n",
       " 'diffus': 3,\n",
       " 'interstiti': 1,\n",
       " 'pattern': 189,\n",
       " 'test': 438,\n",
       " 'val': 2,\n",
       " 'subfold': 15,\n",
       " 'pneumonianorm': 2,\n",
       " 'jpeg': 11,\n",
       " 'anteriorposterior': 1,\n",
       " 'retrospect': 7,\n",
       " 'cohort': 6,\n",
       " 'pediatr': 4,\n",
       " 'old': 66,\n",
       " 'guangzhou': 3,\n",
       " 'woman': 167,\n",
       " 'children': 11,\n",
       " 'medic': 108,\n",
       " 'center': 313,\n",
       " 'routin': 13,\n",
       " 'clinic': 58,\n",
       " 'care': 133,\n",
       " 'radiograph': 4,\n",
       " 'initi': 159,\n",
       " 'screen': 76,\n",
       " 'control': 190,\n",
       " 'low': 129,\n",
       " 'unread': 2,\n",
       " 'scan': 72,\n",
       " 'diagnosi': 31,\n",
       " 'grade': 116,\n",
       " 'expert': 35,\n",
       " 'physician': 14,\n",
       " 'system': 608,\n",
       " 'error': 115,\n",
       " 'evalu': 185,\n",
       " 'third': 102,\n",
       " 'acknowledgementsdata': 72,\n",
       " 'inspirationautom': 2,\n",
       " 'method': 214,\n",
       " 'detect': 266,\n",
       " 'human': 334,\n",
       " 'diseas': 186,\n",
       " 'christma': 14,\n",
       " 'recip': 25,\n",
       " 'cook': 18,\n",
       " 'put': 60,\n",
       " 'togeth': 90,\n",
       " 'common': 312,\n",
       " 'practic': 103,\n",
       " 'nlp': 66,\n",
       " 'techniquesfeel': 1,\n",
       " 'run': 177,\n",
       " 'let': 83,\n",
       " 'know': 169,\n",
       " 'improv': 215,\n",
       " 'datasetscrap': 1,\n",
       " 'json': 103,\n",
       " 'line': 247,\n",
       " 'bbc': 2,\n",
       " 'good': 239,\n",
       " 'author': 245,\n",
       " 'ingredi': 17,\n",
       " 'acknowledgementsid': 2,\n",
       " 'acknowledg': 223,\n",
       " 'inspirationyour': 30,\n",
       " 'front': 74,\n",
       " 'answer': 256,\n",
       " 'nba': 69,\n",
       " 'playbyplay': 7,\n",
       " 'log': 57,\n",
       " 'season': 208,\n",
       " 'regular': 53,\n",
       " 'subscript': 9,\n",
       " 'bigdataballcom': 1,\n",
       " 'limit': 187,\n",
       " 'acknowledgementssourc': 10,\n",
       " 'mall': 3,\n",
       " 'segment': 137,\n",
       " 'basket': 12,\n",
       " 'purpos': 205,\n",
       " 'concept': 48,\n",
       " 'known': 145,\n",
       " 'unsupervis': 27,\n",
       " 'techniqu': 124,\n",
       " 'kmean': 11,\n",
       " 'cluster': 110,\n",
       " 'algorithm': 194,\n",
       " 'simplest': 4,\n",
       " 'form': 230,\n",
       " 'owe': 24,\n",
       " 'supermarket': 3,\n",
       " 'membership': 29,\n",
       " 'card': 132,\n",
       " 'basic': 135,\n",
       " 'age': 474,\n",
       " 'gender': 216,\n",
       " 'annual': 268,\n",
       " 'incom': 219,\n",
       " 'spend': 80,\n",
       " 'someth': 71,\n",
       " 'assign': 110,\n",
       " 'defin': 110,\n",
       " 'paramet': 105,\n",
       " 'behavior': 110,\n",
       " 'problem': 204,\n",
       " 'statementy': 1,\n",
       " 'easili': 54,\n",
       " 'converg': 2,\n",
       " 'target': 121,\n",
       " 'sens': 57,\n",
       " 'team': 460,\n",
       " 'strategi': 36,\n",
       " 'accordingli': 6,\n",
       " 'acknowledgementsfrom': 1,\n",
       " 'udemi': 5,\n",
       " 'machin': 354,\n",
       " 'coursei': 1,\n",
       " 'field': 515,\n",
       " 'share': 346,\n",
       " 'knowledg': 82,\n",
       " 'inspirationbi': 5,\n",
       " 'end': 249,\n",
       " 'studi': 302,\n",
       " 'achiev': 101,\n",
       " 'start': 464,\n",
       " 'easi': 89,\n",
       " 'actual': 165,\n",
       " 'respond': 115,\n",
       " 'look': 250,\n",
       " 'filetyp': 2,\n",
       " 'kernel': 244,\n",
       " 'etc': 249,\n",
       " 'super': 31,\n",
       " 'endpoint': 3,\n",
       " 'design': 145,\n",
       " 'sign': 72,\n",
       " 'languag': 606,\n",
       " 'digit': 256,\n",
       " 'bturkey': 1,\n",
       " 'ankara': 4,\n",
       " 'ayranc': 4,\n",
       " 'anadolu': 4,\n",
       " 'high': 259,\n",
       " 'school': 298,\n",
       " 'manual': 88,\n",
       " 'convey': 15,\n",
       " 'simultan': 10,\n",
       " 'employ': 142,\n",
       " 'hand': 123,\n",
       " 'gestur': 55,\n",
       " 'movement': 82,\n",
       " 'orient': 14,\n",
       " 'finger': 21,\n",
       " 'arm': 21,\n",
       " 'bodi': 106,\n",
       " 'facial': 27,\n",
       " 'express': 165,\n",
       " 'speaker': 84,\n",
       " 'previewimg': 1,\n",
       " 'srcurl': 19,\n",
       " 'img': 14,\n",
       " 'detail': 742,\n",
       " 'color': 127,\n",
       " 'space': 141,\n",
       " 'grayscal': 17,\n",
       " 'npi': 10,\n",
       " 'number': 1529,\n",
       " 'class': 386,\n",
       " 'particip': 176,\n",
       " 'student': 241,\n",
       " 'sampl': 494,\n",
       " 'reporepo': 1,\n",
       " 'githubcomardamavisignlanguagedigitsdataseturl': 2,\n",
       " 'rgb': 11,\n",
       " 'turkey': 16,\n",
       " 'schoolurl': 1,\n",
       " 'datasetthi': 10,\n",
       " 'prepar': 86,\n",
       " 'project': 621,\n",
       " 'execut': 53,\n",
       " 'zeynep': 1,\n",
       " 'dikl': 1,\n",
       " 'arda': 2,\n",
       " 'maviturkey': 1,\n",
       " 'datasetfor': 3,\n",
       " 'mavi': 1,\n",
       " 'gist': 5,\n",
       " 'gistgithubcomardamavigetdatasetpyurl': 1,\n",
       " 'person': 363,\n",
       " 'oakland': 127,\n",
       " 'crime': 323,\n",
       " 'california': 141,\n",
       " 'heredataoaklandnetcom': 25,\n",
       " 'domain': 221,\n",
       " 'dedic': 57,\n",
       " 'ethereum': 28,\n",
       " 'blockchain': 24,\n",
       " 'complet': 300,\n",
       " 'live': 154,\n",
       " 'bigqueri': 160,\n",
       " 'bitcoin': 52,\n",
       " 'cryptocurr': 46,\n",
       " 'captur': 121,\n",
       " 'imagin': 15,\n",
       " 'technologist': 1,\n",
       " 'financi': 184,\n",
       " 'economist': 12,\n",
       " 'currenc': 53,\n",
       " 'applic': 319,\n",
       " 'underli': 25,\n",
       " 'technolog': 115,\n",
       " 'predecessor': 8,\n",
       " 'immut': 2,\n",
       " 'ledger': 4,\n",
       " 'howev': 153,\n",
       " 'creator': 18,\n",
       " 'vitalik': 3,\n",
       " 'buterin': 3,\n",
       " 'extend': 38,\n",
       " 'capabl': 17,\n",
       " 'virtual': 38,\n",
       " 'arbitrari': 9,\n",
       " 'smart': 49,\n",
       " 'contractsboth': 1,\n",
       " 'essenti': 35,\n",
       " 'analyt': 98,\n",
       " 'function': 96,\n",
       " 'notabl': 18,\n",
       " 'ether': 2,\n",
       " 'major': 194,\n",
       " 'transfer': 128,\n",
       " 'compos': 68,\n",
       " 'socal': 8,\n",
       " 'token': 75,\n",
       " 'manag': 144,\n",
       " 'precis': 29,\n",
       " 'direct': 139,\n",
       " 'resembl': 4,\n",
       " 'debit': 1,\n",
       " 'credit': 128,\n",
       " 'contrast': 23,\n",
       " 'mechan': 49,\n",
       " 'difficult': 69,\n",
       " 'determin': 177,\n",
       " 'balanc': 38,\n",
       " 'wallet': 4,\n",
       " 'address': 222,\n",
       " 'hold': 45,\n",
       " 'bytecod': 1,\n",
       " 'programmat': 5,\n",
       " 'creation': 53,\n",
       " 'agreement': 68,\n",
       " 'automat': 109,\n",
       " 'trigger': 10,\n",
       " 'decentr': 11,\n",
       " 'autonom': 8,\n",
       " 'ethereumblockchain': 1,\n",
       " 'dailyour': 1,\n",
       " 'readili': 11,\n",
       " 'promot': 30,\n",
       " 'innov': 35,\n",
       " 'increas': 161,\n",
       " 'societ': 2,\n",
       " 'benefit': 80,\n",
       " 'queri': 125,\n",
       " 'tablesy': 15,\n",
       " 'client': 48,\n",
       " 'librari': 169,\n",
       " 'tabl': 347,\n",
       " 'bigquerypublicdatabitcoinblockchaintablenam': 2,\n",
       " 'fork': 38,\n",
       " 'acknowledgementscov': 1,\n",
       " 'photo': 128,\n",
       " 'thought': 43,\n",
       " 'popularli': 1,\n",
       " 'exchang': 53,\n",
       " 'repres': 515,\n",
       " 'transact': 115,\n",
       " 'volum': 133,\n",
       " 'network': 397,\n",
       " 'offic': 239,\n",
       " 'action': 109,\n",
       " 'patent': 158,\n",
       " 'examin': 77,\n",
       " 'access': 329,\n",
       " 'sql': 26,\n",
       " 'bqhelper': 19,\n",
       " 'modul': 44,\n",
       " 'notif': 8,\n",
       " 'decis': 91,\n",
       " 'disclos': 28,\n",
       " 'ground': 87,\n",
       " 'reject': 11,\n",
       " 'claim': 97,\n",
       " 'affect': 102,\n",
       " 'pertin': 3,\n",
       " 'prior': 72,\n",
       " 'art': 74,\n",
       " 'mail': 15,\n",
       " 'period': 290,\n",
       " 'uspto': 58,\n",
       " 'acknowledgementsa': 18,\n",
       " 'paper': 257,\n",
       " 'cite': 197,\n",
       " 'qiang': 1,\n",
       " 'myer': 5,\n",
       " 'amanda': 3,\n",
       " 'beliveau': 1,\n",
       " 'scott': 11,\n",
       " 'prosecut': 37,\n",
       " 'unlock': 6,\n",
       " 'trait': 12,\n",
       " 'econom': 319,\n",
       " 'ssrn': 1,\n",
       " 'externalthi': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "for k, v in list(final_dict.items()):\n",
    "    bag_of_words.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30630"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = np.array(bag_of_words)\n",
    "bag_of_words = np.unique(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bag = dict()\n",
    "for i in range(len(bag_of_words)):\n",
    "    final_bag[bag_of_words[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving bag of words as array object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/bag_of_words.npy', 'wb') as f:\n",
    "    np.save(f,bag_of_words,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./Data/data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = ps.read_csv('./Data/data_clean.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'title', 'subtitle', 'description', 'keywords', 'url',\n",
       "       'url_index', 'tokenized_title', 'tokenized_subtitle',\n",
       "       'tokenized_description', 'doc', 'word_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>url</th>\n",
       "      <th>url_index</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_subtitle</th>\n",
       "      <th>tokenized_description</th>\n",
       "      <th>doc</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wine reviews</td>\n",
       "      <td>130k wine reviews with variety location winery...</td>\n",
       "      <td>after watching sommurl a documentary on master...</td>\n",
       "      <td>[food and drink, critical theory, medium, feat...</td>\n",
       "      <td>https://www.kaggle.com/zynicide/wine-reviews</td>\n",
       "      <td>4179</td>\n",
       "      <td>[wine, reviews]</td>\n",
       "      <td>[130k, wine, reviews, with, variety, location,...</td>\n",
       "      <td>[after, watching, sommurl, a, documentary, on,...</td>\n",
       "      <td>[wine, review, wine, review, varieti, locat, w...</td>\n",
       "      <td>{'wine': 10, 'review': 7, 'varieti': 3, 'locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ufo sightings  air quality</td>\n",
       "      <td>ufo usa  lights  air quality usa  pollutants l...</td>\n",
       "      <td>this dataset is the result of the fusion of tw...</td>\n",
       "      <td>[climate, space, earth sciences, timelines, na...</td>\n",
       "      <td>https://www.kaggle.com/infof422henni/ufo-air-q...</td>\n",
       "      <td>1648</td>\n",
       "      <td>[ufo, sightings, air, quality]</td>\n",
       "      <td>[ufo, usa, lights, air, quality, usa, pollutan...</td>\n",
       "      <td>[this, dataset, is, the, result, of, the, fusi...</td>\n",
       "      <td>[ufo, sight, air, qualiti, ufo, usa, light, ai...</td>\n",
       "      <td>{'ufo': 4, 'sight': 4, 'air': 3, 'qualiti': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safebooru  anime image metadata</td>\n",
       "      <td>19 million rows of tagbased anime image metadata</td>\n",
       "      <td>safebooru1 is a tagbased image archive maintai...</td>\n",
       "      <td>[popular culture, visual arts, animation, draw...</td>\n",
       "      <td>https://www.kaggle.com/alamson/safebooru</td>\n",
       "      <td>169</td>\n",
       "      <td>[safebooru, anime, image, metadata]</td>\n",
       "      <td>[19, million, rows, of, tagbased, anime, image...</td>\n",
       "      <td>[safebooru1, is, a, tagbased, image, archive, ...</td>\n",
       "      <td>[safebooru, anim, imag, metadata, million, row...</td>\n",
       "      <td>{'safebooru': 2, 'anim': 3, 'imag': 7, 'metada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quickdraw sketches</td>\n",
       "      <td>sketches and strokes from the quickdraw game</td>\n",
       "      <td>the dataset consists of the series of strokes ...</td>\n",
       "      <td>[image processing, visual arts, drawing, large...</td>\n",
       "      <td>https://www.kaggle.com/google/tinyquickdraw</td>\n",
       "      <td>1465</td>\n",
       "      <td>[quickdraw, sketches]</td>\n",
       "      <td>[sketches, and, strokes, from, the, quickdraw,...</td>\n",
       "      <td>[the, dataset, consists, of, the, series, of, ...</td>\n",
       "      <td>[quickdraw, sketch, sketch, stroke, quickdraw,...</td>\n",
       "      <td>{'quickdraw': 3, 'sketch': 2, 'stroke': 5, 'ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeg microexperiment</td>\n",
       "      <td>music vs reading 34 min per condition</td>\n",
       "      <td>this is a tiny selfexperiment the researcher c...</td>\n",
       "      <td>[neuroscience, biotechnology, small, featured]</td>\n",
       "      <td>https://www.kaggle.com/millerintllc/eeg-microe...</td>\n",
       "      <td>2227</td>\n",
       "      <td>[eeg, microexperiment]</td>\n",
       "      <td>[music, vs, reading, 34, min, per, condition]</td>\n",
       "      <td>[this, is, a, tiny, selfexperiment, the, resea...</td>\n",
       "      <td>[eeg, microexperi, music, read, min, per, cond...</td>\n",
       "      <td>{'eeg': 3, 'microexperi': 1, 'music': 3, 'read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>selu with good init 2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[small]</td>\n",
       "      <td>https://www.kaggle.com/hypdeb/selu-with-good-i...</td>\n",
       "      <td>1615</td>\n",
       "      <td>[selu, with, good, init, 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[selu, good, init]</td>\n",
       "      <td>{'selu': 1, 'good': 1, 'init': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>price per product</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[small]</td>\n",
       "      <td>https://www.kaggle.com/azizabidi/price-per-pro...</td>\n",
       "      <td>391</td>\n",
       "      <td>[price, per, product]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[price, per, product]</td>\n",
       "      <td>{'price': 1, 'per': 1, 'product': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>japan trade stats custom 2016 data</td>\n",
       "      <td>sub set of japantradestatistics</td>\n",
       "      <td>sub dataset of japan trade statistics url 2016...</td>\n",
       "      <td>[finance, business, medium]</td>\n",
       "      <td>https://www.kaggle.com/zanjibar/custom-2016</td>\n",
       "      <td>4136</td>\n",
       "      <td>[japan, trade, stats, custom, 2016, data]</td>\n",
       "      <td>[sub, set, of, japantradestatistics]</td>\n",
       "      <td>[sub, dataset, of, japan, trade, statistics, u...</td>\n",
       "      <td>[japan, trade, stat, custom, data, sub, set, j...</td>\n",
       "      <td>{'japan': 2, 'trade': 2, 'stat': 1, 'custom': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>us flights data 2008</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[medium]</td>\n",
       "      <td>https://www.kaggle.com/vikalpdongre/us-flights...</td>\n",
       "      <td>3968</td>\n",
       "      <td>[us, flights, data, 2008]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[flight, data]</td>\n",
       "      <td>{'flight': 1, 'data': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>iowa house prices</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[small]</td>\n",
       "      <td>https://www.kaggle.com/nickptaylor/iowa-house-...</td>\n",
       "      <td>2656</td>\n",
       "      <td>[iowa, house, prices]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[iowa, hous, price]</td>\n",
       "      <td>{'iowa': 1, 'hous': 1, 'price': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4620 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                           wine reviews   \n",
       "1             ufo sightings  air quality   \n",
       "2        safebooru  anime image metadata   \n",
       "3                     quickdraw sketches   \n",
       "4                    eeg microexperiment   \n",
       "...                                  ...   \n",
       "4615               selu with good init 2   \n",
       "4616                   price per product   \n",
       "4617  japan trade stats custom 2016 data   \n",
       "4618                us flights data 2008   \n",
       "4619                   iowa house prices   \n",
       "\n",
       "                                               subtitle  \\\n",
       "0     130k wine reviews with variety location winery...   \n",
       "1     ufo usa  lights  air quality usa  pollutants l...   \n",
       "2      19 million rows of tagbased anime image metadata   \n",
       "3          sketches and strokes from the quickdraw game   \n",
       "4                 music vs reading 34 min per condition   \n",
       "...                                                 ...   \n",
       "4615                                                      \n",
       "4616                                                      \n",
       "4617                    sub set of japantradestatistics   \n",
       "4618                                                      \n",
       "4619                                                      \n",
       "\n",
       "                                            description  \\\n",
       "0     after watching sommurl a documentary on master...   \n",
       "1     this dataset is the result of the fusion of tw...   \n",
       "2     safebooru1 is a tagbased image archive maintai...   \n",
       "3     the dataset consists of the series of strokes ...   \n",
       "4     this is a tiny selfexperiment the researcher c...   \n",
       "...                                                 ...   \n",
       "4615                                                      \n",
       "4616                                                      \n",
       "4617  sub dataset of japan trade statistics url 2016...   \n",
       "4618                                                      \n",
       "4619                                                      \n",
       "\n",
       "                                               keywords  \\\n",
       "0     [food and drink, critical theory, medium, feat...   \n",
       "1     [climate, space, earth sciences, timelines, na...   \n",
       "2     [popular culture, visual arts, animation, draw...   \n",
       "3     [image processing, visual arts, drawing, large...   \n",
       "4        [neuroscience, biotechnology, small, featured]   \n",
       "...                                                 ...   \n",
       "4615                                            [small]   \n",
       "4616                                            [small]   \n",
       "4617                        [finance, business, medium]   \n",
       "4618                                           [medium]   \n",
       "4619                                            [small]   \n",
       "\n",
       "                                                    url  url_index  \\\n",
       "0          https://www.kaggle.com/zynicide/wine-reviews       4179   \n",
       "1     https://www.kaggle.com/infof422henni/ufo-air-q...       1648   \n",
       "2              https://www.kaggle.com/alamson/safebooru        169   \n",
       "3           https://www.kaggle.com/google/tinyquickdraw       1465   \n",
       "4     https://www.kaggle.com/millerintllc/eeg-microe...       2227   \n",
       "...                                                 ...        ...   \n",
       "4615  https://www.kaggle.com/hypdeb/selu-with-good-i...       1615   \n",
       "4616  https://www.kaggle.com/azizabidi/price-per-pro...        391   \n",
       "4617        https://www.kaggle.com/zanjibar/custom-2016       4136   \n",
       "4618  https://www.kaggle.com/vikalpdongre/us-flights...       3968   \n",
       "4619  https://www.kaggle.com/nickptaylor/iowa-house-...       2656   \n",
       "\n",
       "                                tokenized_title  \\\n",
       "0                               [wine, reviews]   \n",
       "1                [ufo, sightings, air, quality]   \n",
       "2           [safebooru, anime, image, metadata]   \n",
       "3                         [quickdraw, sketches]   \n",
       "4                        [eeg, microexperiment]   \n",
       "...                                         ...   \n",
       "4615                [selu, with, good, init, 2]   \n",
       "4616                      [price, per, product]   \n",
       "4617  [japan, trade, stats, custom, 2016, data]   \n",
       "4618                  [us, flights, data, 2008]   \n",
       "4619                      [iowa, house, prices]   \n",
       "\n",
       "                                     tokenized_subtitle  \\\n",
       "0     [130k, wine, reviews, with, variety, location,...   \n",
       "1     [ufo, usa, lights, air, quality, usa, pollutan...   \n",
       "2     [19, million, rows, of, tagbased, anime, image...   \n",
       "3     [sketches, and, strokes, from, the, quickdraw,...   \n",
       "4         [music, vs, reading, 34, min, per, condition]   \n",
       "...                                                 ...   \n",
       "4615                                                 []   \n",
       "4616                                                 []   \n",
       "4617               [sub, set, of, japantradestatistics]   \n",
       "4618                                                 []   \n",
       "4619                                                 []   \n",
       "\n",
       "                                  tokenized_description  \\\n",
       "0     [after, watching, sommurl, a, documentary, on,...   \n",
       "1     [this, dataset, is, the, result, of, the, fusi...   \n",
       "2     [safebooru1, is, a, tagbased, image, archive, ...   \n",
       "3     [the, dataset, consists, of, the, series, of, ...   \n",
       "4     [this, is, a, tiny, selfexperiment, the, resea...   \n",
       "...                                                 ...   \n",
       "4615                                                 []   \n",
       "4616                                                 []   \n",
       "4617  [sub, dataset, of, japan, trade, statistics, u...   \n",
       "4618                                                 []   \n",
       "4619                                                 []   \n",
       "\n",
       "                                                    doc  \\\n",
       "0     [wine, review, wine, review, varieti, locat, w...   \n",
       "1     [ufo, sight, air, qualiti, ufo, usa, light, ai...   \n",
       "2     [safebooru, anim, imag, metadata, million, row...   \n",
       "3     [quickdraw, sketch, sketch, stroke, quickdraw,...   \n",
       "4     [eeg, microexperi, music, read, min, per, cond...   \n",
       "...                                                 ...   \n",
       "4615                                 [selu, good, init]   \n",
       "4616                              [price, per, product]   \n",
       "4617  [japan, trade, stat, custom, data, sub, set, j...   \n",
       "4618                                     [flight, data]   \n",
       "4619                                [iowa, hous, price]   \n",
       "\n",
       "                                             word_count  \n",
       "0     {'wine': 10, 'review': 7, 'varieti': 3, 'locat...  \n",
       "1     {'ufo': 4, 'sight': 4, 'air': 3, 'qualiti': 3,...  \n",
       "2     {'safebooru': 2, 'anim': 3, 'imag': 7, 'metada...  \n",
       "3     {'quickdraw': 3, 'sketch': 2, 'stroke': 5, 'ga...  \n",
       "4     {'eeg': 3, 'microexperi': 1, 'music': 3, 'read...  \n",
       "...                                                 ...  \n",
       "4615                  {'selu': 1, 'good': 1, 'init': 1}  \n",
       "4616               {'price': 1, 'per': 1, 'product': 1}  \n",
       "4617  {'japan': 2, 'trade': 2, 'stat': 1, 'custom': ...  \n",
       "4618                           {'flight': 1, 'data': 1}  \n",
       "4619                 {'iowa': 1, 'hous': 1, 'price': 1}  \n",
       "\n",
       "[4620 rows x 11 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_index</th>\n",
       "      <th>url</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4179</td>\n",
       "      <td>https://www.kaggle.com/zynicide/wine-reviews</td>\n",
       "      <td>[wine, review, wine, review, varieti, locat, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1648</td>\n",
       "      <td>https://www.kaggle.com/infof422henni/ufo-air-q...</td>\n",
       "      <td>[ufo, sight, air, qualiti, ufo, usa, light, ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169</td>\n",
       "      <td>https://www.kaggle.com/alamson/safebooru</td>\n",
       "      <td>[safebooru, anim, imag, metadata, million, row...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465</td>\n",
       "      <td>https://www.kaggle.com/google/tinyquickdraw</td>\n",
       "      <td>[quickdraw, sketch, sketch, stroke, quickdraw,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2227</td>\n",
       "      <td>https://www.kaggle.com/millerintllc/eeg-microe...</td>\n",
       "      <td>[eeg, microexperi, music, read, min, per, cond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>1615</td>\n",
       "      <td>https://www.kaggle.com/hypdeb/selu-with-good-i...</td>\n",
       "      <td>[selu, good, init]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>391</td>\n",
       "      <td>https://www.kaggle.com/azizabidi/price-per-pro...</td>\n",
       "      <td>[price, per, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>4136</td>\n",
       "      <td>https://www.kaggle.com/zanjibar/custom-2016</td>\n",
       "      <td>[japan, trade, stat, custom, data, sub, set, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>3968</td>\n",
       "      <td>https://www.kaggle.com/vikalpdongre/us-flights...</td>\n",
       "      <td>[flight, data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>2656</td>\n",
       "      <td>https://www.kaggle.com/nickptaylor/iowa-house-...</td>\n",
       "      <td>[iowa, hous, price]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      url_index                                                url  \\\n",
       "0          4179       https://www.kaggle.com/zynicide/wine-reviews   \n",
       "1          1648  https://www.kaggle.com/infof422henni/ufo-air-q...   \n",
       "2           169           https://www.kaggle.com/alamson/safebooru   \n",
       "3          1465        https://www.kaggle.com/google/tinyquickdraw   \n",
       "4          2227  https://www.kaggle.com/millerintllc/eeg-microe...   \n",
       "...         ...                                                ...   \n",
       "4615       1615  https://www.kaggle.com/hypdeb/selu-with-good-i...   \n",
       "4616        391  https://www.kaggle.com/azizabidi/price-per-pro...   \n",
       "4617       4136        https://www.kaggle.com/zanjibar/custom-2016   \n",
       "4618       3968  https://www.kaggle.com/vikalpdongre/us-flights...   \n",
       "4619       2656  https://www.kaggle.com/nickptaylor/iowa-house-...   \n",
       "\n",
       "                                                    doc  \n",
       "0     [wine, review, wine, review, varieti, locat, w...  \n",
       "1     [ufo, sight, air, qualiti, ufo, usa, light, ai...  \n",
       "2     [safebooru, anim, imag, metadata, million, row...  \n",
       "3     [quickdraw, sketch, sketch, stroke, quickdraw,...  \n",
       "4     [eeg, microexperi, music, read, min, per, cond...  \n",
       "...                                                 ...  \n",
       "4615                                 [selu, good, init]  \n",
       "4616                              [price, per, product]  \n",
       "4617  [japan, trade, stat, custom, data, sub, set, j...  \n",
       "4618                                     [flight, data]  \n",
       "4619                                [iowa, hous, price]  \n",
       "\n",
       "[4620 rows x 3 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['url_index','url','doc']]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
